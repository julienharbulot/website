<!doctype html>
<html lang="en">
    <head>
    

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-166292985-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-166292985-1');
    </script>
    

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" 
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons"
          rel="stylesheet" crossorigin="anonymous">
    
    <link rel="stylesheet" href="/theme/pygment-github.css">
    <link rel="stylesheet" href="/theme/article.css"> 

    <title>Scraping with Python3 and Scrapy</title>
    
    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="/images/favicon/site.webmanifest">
    <link rel="mask-icon" href="/images/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="/images/favicon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    
<!-- Mathjax -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG">
  MathJax.Hub.Config({
    tex2jax: {
    	inlineMath: [ ['$','$'] ],
    	processEscapes: true
    },
	"HTML-CSS": {
		fonts: ["TeX"] 
	}
  });
</script>

    </head>

    <body>
    
    <nav class="navbar navbar-expand-lg navbar-light ">
        <a class="navbar-brand" href="//julienharbulot.com/index.html"><img src="//julienharbulot.com/images/logo.png" width="30" alt=""></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/technical-blog.html">Technical blog</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/maths.html">Maths</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/projects.html">Projects</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/research.html">Research</a>
            </li>
            
            <!--<li class="nav-item">
                <a class="nav-link" href="//julienharbulot.com/about-me.html">About me</a>
            </li>-->
            

<li class="nav-item dropdown">
    <a class="nav-link active dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
        Table of content
    </a>
    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
        <div class="toc"><ul>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#the-scrapy-shell' title='The Scrapy Shell'>The Scrapy Shell</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#a-scrapy-project' title='A Scrapy project'>A Scrapy project</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#useful-settings' title='Useful settings'>Useful settings</a>
    <ul>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#first-spider' title='First spider'>First spider</a>
    </li>
    </ul>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#read-next' title='Read next'>Read next</a>
</li>
</ul><div>
    </div>
</li>


            </ul>
        </div>
    </nav>
    
    
    
    <div class="container">
    <div class="row mt-5">
      <div class="col-lg-8 mx-auto"> 
        <h1 class="display-5">Scraping with Python3 and Scrapy </h1>
        <div class="text-right">11 Jun 2018</div>
      </div>
    </div>
    <div class="row mt-5">
    <article class="col-lg-8 mx-auto">
    <p>
<script type="math/tex; mode=display">
\def\sa{a}
\def\sb{b}
\def\sc{c}
\def\sd{d}
\def\se{e}
\def\sf{f}
\def\sg{g}
\def\sh{h}
\def\si{i}
\def\sj{j}
\def\sk{k}
\def\sl{l}
\def\sm{m}
\def\sn{n}
\def\so{o}
\def\sp{p}
\def\sq{q}
\def\sr{r}
\def\ss{s}
\def\st{t}
\def\su{u}
\def\sv{v}
\def\sw{w}
\def\sx{x}
\def\sy{y}
\def\sz{z}
\def\va{\vec{a}}
\def\vb{\vec{b}}
\def\vc{\vec{c}}
\def\vd{\vec{d}}
\def\ve{\vec{e}}
\def\vf{\vec{f}}
\def\vg{\vec{g}}
\def\vh{\vec{h}}
\def\vi{\vec{i}}
\def\vj{\vec{j}}
\def\vk{\vec{k}}
\def\vl{\vec{l}}
\def\vm{\vec{m}}
\def\vn{\vec{n}}
\def\vo{\vec{o}}
\def\vp{\vec{p}}
\def\vq{\vec{q}}
\def\vr{\vec{r}}
\def\vs{\vec{s}}
\def\vt{\vec{t}}
\def\vu{\vec{u}}
\def\vv{\vec{v}}
\def\vw{\vec{w}}
\def\vx{\vec{x}}
\def\vy{\vec{y}}
\def\vz{\vec{z}}
\def\ga{\mathfrak{A}}
\def\gb{\mathfrak{B}}
\def\gc{\mathfrak{C}}
\def\gd{\mathfrak{D}}
\def\ge{\mathfrak{E}}
\def\gf{\mathfrak{F}}
\def\gg{\mathfrak{G}}
\def\gh{\mathfrak{H}}
\def\gi{\mathfrak{I}}
\def\gj{\mathfrak{J}}
\def\gk{\mathfrak{K}}
\def\gl{\mathfrak{L}}
\def\gm{\mathfrak{M}}
\def\gn{\mathfrak{N}}
\def\go{\mathfrak{O}}
\def\gp{\mathfrak{P}}
\def\gq{\mathfrak{Q}}
\def\gr{\mathfrak{R}}
\def\gs{\mathfrak{S}}
\def\gt{\mathfrak{T}}
\def\gu{\mathfrak{U}}
\def\gv{\mathfrak{V}}
\def\gw{\mathfrak{W}}
\def\gx{\mathfrak{X}}
\def\gy{\mathfrak{Y}}
\def\gz{\mathfrak{Z}}
\def\ra{A}
\def\rb{B}
\def\rc{C}
\def\rd{D}
\def\re{E}
\def\rf{F}
\def\rg{G}
\def\rh{H}
\def\ri{I}
\def\rj{J}
\def\rk{K}
\def\rl{L}
\def\rm{M}
\def\rn{N}
\def\ro{O}
\def\rp{P}
\def\rq{Q}
\def\rr{R}
\def\rs{S}
\def\rt{T}
\def\ru{U}
\def\rv{V}
\def\rw{W}
\def\rx{X}
\def\ry{Y}
\def\rz{Z}
\def\rva{\vec{A}}
\def\rvb{\vec{B}}
\def\rvc{\vec{C}}
\def\rvd{\vec{D}}
\def\rve{\vec{E}}
\def\rvf{\vec{F}}
\def\rvg{\vec{G}}
\def\rvh{\vec{H}}
\def\rvi{\vec{I}}
\def\rvj{\vec{J}}
\def\rvk{\vec{K}}
\def\rvl{\vec{L}}
\def\rvm{\vec{M}}
\def\rvn{\vec{N}}
\def\rvo{\vec{O}}
\def\rvp{\vec{P}}
\def\rvq{\vec{Q}}
\def\rvr{\vec{R}}
\def\rvs{\vec{S}}
\def\rvt{\vec{T}}
\def\rvu{\vec{U}}
\def\rvv{\vec{V}}
\def\rvw{\vec{W}}
\def\rvx{\vec{X}}
\def\rvy{\vec{Y}}
\def\rvz{\vec{Z}}
\def\seta{A}
\def\setb{B}
\def\setc{C}
\def\setd{D}
\def\sete{E}
\def\setf{F}
\def\setg{G}
\def\seth{H}
\def\seti{I}
\def\setj{J}
\def\setk{K}
\def\setl{L}
\def\setm{M}
\def\setn{N}
\def\seto{O}
\def\setp{P}
\def\setq{Q}
\def\setr{R}
\def\sets{S}
\def\sett{T}
\def\setu{U}
\def\setv{V}
\def\setw{W}
\def\setx{X}
\def\sety{Y}
\def\setz{Z}
\def\fa{a}
\def\fb{b}
\def\fc{c}
\def\fd{d}
\def\fe{e}
\def\ff{f}
\def\fg{g}
\def\fh{h}
\def\fi{i}
\def\fj{j}
\def\fk{k}
\def\fl{l}
\def\fm{m}
\def\fn{n}
\def\fo{o}
\def\fp{p}
\def\fq{q}
\def\fr{r}
\def\fs{s}
\def\ft{t}
\def\fu{u}
\def\fv{v}
\def\fw{w}
\def\fx{x}
\def\fy{y}
\def\fz{z}
\def\fA{A}
\def\fB{B}
\def\fC{C}
\def\fD{D}
\def\fE{E}
\def\fF{F}
\def\fG{G}
\def\fH{H}
\def\fI{I}
\def\fJ{J}
\def\fK{K}
\def\fL{L}
\def\fM{M}
\def\fN{N}
\def\fO{O}
\def\fP{P}
\def\fQ{Q}
\def\fR{R}
\def\fS{S}
\def\fT{T}
\def\fU{U}
\def\fV{V}
\def\fW{W}
\def\fX{X}
\def\fY{Y}
\def\fZ{Z}
\def\ma{A}
\def\mb{B}
\def\mc{C}
\def\md{D}
\def\me{E}
\def\mf{F}
\def\mg{G}
\def\mh{H}
\def\mi{I}
\def\mj{J}
\def\mk{K}
\def\ml{L}
\def\mm{M}
\def\mn{N}
\def\mo{O}
\def\mp{P}
\def\mq{Q}
\def\mr{R}
\def\ms{S}
\def\mt{T}
\def\matu{U}
\def\mv{V}
\def\mw{W}
\def\mx{X}
\def\my{Y}
\def\mz{Z}
\def\loss{\mathcal{L}}
\newcommand{\dkl}[2]{D_{\text{KL}}\mathopen{}\paren{#1\,||\,#2}}
\newcommand{\dataset}{S}
\newcommand{\ndataset}{N}
\newcommand{\idataset}{n}
\newcommand{\inputRV}{\mathcal{X}}
\newcommand{\inputvec}{\vec{x}}
\newcommand{\ninputvec}[1]{\vec{x}_{#1}}
\newcommand{\iinputvec}[1]{x_{#1}}
\newcommand{\niinputvec}[2]{x_{#1, #2}}
\newcommand{\icpnt}{i}
\newcommand{\inputmatrix}{X}
\newcommand{\inputdim}{D}
\newcommand{\outputval}{y}
\newcommand{\ioutputval}[1]{y_{#1}}
\newcommand{\outputvec}{\vec{y}}
\newcommand{\trainset}{S_{\text{train}}}
\newcommand{\testset}{S_{\text{test}}}
\newcommand{\truemodel}{f_{\text{true}}}
\newcommand{\trainedmodel}{f_{\trainset}}
\newcommand{\linmodel}[1]{f_{#1}}
\newcommand{\bestmodel}{f^{*}}
\newcommand{\model}{f}
\newcommand{\hyperparam}{\lambda}
\newcommand{\linparamv}{\vec{w}}
\newcommand{\ilinparam}[1]{w_{#1}}
\newcommand{\indivloss}{l}
\newcommand{\modelclass}{\mathcal{F}}
\newcommand{\linclass}{\modelclass_{\text{lin}}}
\newcommand{\g}{\mathcal{G}}
\newcommand{\gmse}{\g_{\text{MSE}}}
\newcommand{\glasso}{\g_{\text{lasso}}}
\newcommand{\gridge}{\g_{\text{ridge}}}
\newcommand{\glogit}{\g_{\logit}}
\newcommand{\l}{\mathcal{L}}
\newcommand{\lmse}{\l_{\text{MSE}}}
\newcommand{\lmae}{\l_{\text{MAE}}}
\newcommand{\llasso}{\l_{\text{lasso}}}
\newcommand{\lridge}{\l_{\text{ridge}}}
\newcommand{\llogit}{\l_{\logit}}
\newcommand{\logit}{\sigma}
\newcommand{\reg}{\mathcal{R}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\mean}{mean}
\DeclareMathOperator*{\avg}{avg}
\DeclareMathOperator*{\span}{span}
\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\bias}{bias}
\newcommand{\expectation}{\mathbb{E}}
\newcommand{\brak}[1]{\left[#1\right]}
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\realset}{\mathbb{R}}
\newcommand{\realvset}[1]{\realset^{#1}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\gaussian}{\mathcal{N}}
\newcommand{\iid}{\stackrel{\text{i.i.d.}}{\sim}}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\normtwo}[1]{\norm{#1}_{2}}
\newcommand{\normone}[1]{\norm{#1}_{1}}
\newcommand{\card}[1]{\left\lvert#1\right\rvert}
\newcommand{\grad}{\nabla}
\newcommand{\dconv}{\stackrel{d}{\to}}
\newcommand{\pconv}{\stackrel{p}{\to}}
\newcommand{\rva}[1]{#1}
\newcommand{\rve}[1]{\vec{#1}}
\newcommand{\obs}[1]{#1}
\newcommand{\vobs}[1]{\vec{#1}}
\newcommand{\distrib}[1]{#1}
\newcommand{\distribof}[2]{#1_{#2}}
\newcommand{\density}[1]{#1}
\newcommand{\densityof}[2]{#1_{#2}}
\newcommand{\distributed}{\sim}
\newcommand{\const}[1]{#1}
\newcommand{\fun}[1]{#1}
</script>
</p>
<div class="typography">

<p>Scrapy is one of the most popular Python framework for large scale web scraping. It gives you all the tools you need to efficiently extract data from websites, process them as you want, and store them in your preferred structure and format. It has good documentation and lots of “get started quick” tutorials all over the web.</p>
<p>In a previous article, we build a very simple <a href="{filename}scraping-python-urllib.mkd">web crawler for scraping using urllib</a>. If we were to expand it with proper error handling, ability to pause and resume, connecting reliably to websites… we would end up building a scraping framework similar to <em>scrapy</em>.</p>
<p>Scrapy takes care of error handing, parallel processing which is already much more than what our simple script did.</p>
<p>The first step is to install the Scrapy library (<a href="https://doc.scrapy.org/en/latest/intro/install.html">install guide</a>):</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">scrapy</span>
</code></pre></div></div>
<h2 id="the-scrapy-shell">The Scrapy Shell</h2>
<p>Scrapy offers a shell that is useful to test the effect of a method or to explore a webpage. For instance:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">scrapy</span> <span class="n">shell</span>

<span class="n">In</span>  <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">fetch</span><span class="p">(</span><span class="s">"https://medium.com/s/journalists-are-wrong-about-health/health-is-more-complicated-than-correlations-5436cee51b0c"</span><span class="p">)</span> 
<span class="n">Out</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span>

<span class="n">In</span>  <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">"h1::text, h2::text, h3::text"</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="n">Out</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<span class="p">[</span><span class="s">'Health Is More Complicated Than Correlations'</span><span class="p">,</span>
 <span class="s">'The Big Scary Study'</span><span class="p">,</span>
 <span class="s">'Ice Cream Doesn’t Cause Drownings'</span><span class="p">,</span>
 <span class="s">'Scary Studies And Correlations'</span><span class="p">,</span>
 <span class="s">'Observational Causation'</span><span class="p">,</span>
 <span class="s">'Spotting the Scary'</span><span class="p">,</span>
 <span class="s">'Gid M-K; Health Nerd'</span><span class="p">]</span>
</code></pre></div></div>
<p>When using the shell, you might want to define custom functions and reuse them accross sessions. This can be achieved by putting them in a file <code class="highlighter-rouge">myfunctions.py</code> and then sourcing that file from the scrapy shell using <code class="highlighter-rouge">run myfunctions.py</code>. After that, you can call your custom functions right away.</p>
<p>To exit the shell, type <code class="highlighter-rouge">ctrl+d</code>.</p>
<p>Learn more about this feature in the <a href="https://doc.scrapy.org/en/latest/topics/shell.html">shell documentation</a>.</p>
<h2 id="a-scrapy-project">A Scrapy project</h2>
<p>Let’s see how to create a real project using scrapy (Link to <a href="https://doc.scrapy.org/en/latest/intro/tutorial.html">official doc</a>).</p>
<p>First, open your terminal, move to the directory where you want to work and run this command to create a new project called <code class="highlighter-rouge">googleScraper</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scrapy startproject googleScraper
<span class="nb">cd </span>googleScraper
</code></pre></div></div>
<h2 id="useful-settings">Useful settings</h2>
<p>In order to scrape websites regardless of their <code class="highlighter-rouge">robot.txt</code> file (which is bad but convenient), edit the file <code class="highlighter-rouge">settings.py</code> and change the line <code class="highlighter-rouge">ROBOTSTXT_OBEY = True</code> to:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ROBOTSTXT_OBEY</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div>
<p>You’ll notice that the logs are pretty verbose and difficult to read while running the code. That’s because the default <code class="highlighter-rouge">LOG_LEVEL</code> is set to <code class="highlighter-rouge">DEBUG</code>. My advice is to add the following line in <code class="highlighter-rouge">settings.py</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LOG_LEVEL <span class="o">=</span> <span class="s1">'INFO'</span>
</code></pre></div></div>
<p>To change the user-agent of your spider, add a line to <code class="highlighter-rouge">settings.py</code>. For instance:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>USER_AGENT <span class="o">=</span> <span class="s2">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36"</span>
</code></pre></div></div>
<h3 id="first-spider">First spider</h3>
<p>Then, you need to write a <em>spider</em>. a spider is a class that you define and that Scrapy uses to scrape information from a website. A custom spider must subclass <code class="highlighter-rouge">scrapy.Spider</code> and define the following methods:</p>
<ul>
<li><code class="highlighter-rouge">name</code>: uniquely identifies the spider;</li>
<li><code class="highlighter-rouge">start_urls</code>: a list of urls the crawler will begin to crawl from; alternatively you can define <code class="highlighter-rouge">start_requests()</code> (see the doc);</li>
<li><code class="highlighter-rouge">parse()</code>: the method to handle to responses to each requests, this is where you extract data and find new URL to explore.</li>
</ul>
<p>Navigate to <code class="highlighter-rouge">googleScraper/spiders</code> and create a new file <code class="highlighter-rouge">google_spider.py</code>. Before the code of the spider itself, I copied the <code class="highlighter-rouge">filter_urls</code> function from my previous article : <a href="{filename}scraping-python-urllib.mkd">Scraping with python and urllib</a>.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="c"># file googleScraper/spiders/google_spider.py</span>
<span class="c">#</span>

<span class="c">#-----------------------------------------------------</span>
<span class="c"># Code to parse URL (as used in previous article)</span>

<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlparse</span>

<span class="n">netloc</span> <span class="o">=</span> <span class="s">'www.google.ch'</span>

<span class="k">def</span> <span class="nf">has_bad_format</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">exts</span> <span class="o">=</span> <span class="p">[</span><span class="s">'.gif'</span><span class="p">,</span> <span class="s">'.png'</span><span class="p">,</span> <span class="s">'.jpg'</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">url</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">ext</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">exts</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">filter_urls</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">netloc</span><span class="p">):</span>
    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">url</span> <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span> <span class="k">if</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">netloc</span> <span class="o">==</span> <span class="n">netloc</span><span class="p">]</span>
    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">url</span> <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">has_bad_format</span><span class="p">(</span><span class="n">url</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">urls</span>

<span class="c">#-----------------------------------------------------</span>
<span class="c"># Code for scrapy's spider</span>

<span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">GoogleSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="c"># This will be used to run the spider</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"google"</span>

    <span class="c"># Keep our spider on google's domain</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="n">netloc</span><span class="p">]</span>

    <span class="c"># The crawler will start with those URL's</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">'https://'</span> <span class="o">+</span> <span class="n">netloc</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="c"># The function to handle the server's responses</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">'Processing {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span> <span class="o">!=</span> <span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">==&gt; Redirected to {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">))</span>

        <span class="c"># Use CSS selector to extract href urls</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="n">filter_urls</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">netloc</span><span class="p">)</span>

        <span class="c"># Follow the links</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div></div>
<p>You can see in the code that Scrapy takes care of duplicate URLS for us, but we still have to filter urls manually. Actually, <code class="highlighter-rouge">allowed_domains</code> already prevents the spider to go too far, but there are still some <a href="https://github.com/scrapy/scrapy/issues/3217">bugs</a> so it’s a good idea to filter manually.</p>
<p>If you don’t know what the <code class="highlighter-rouge">yield</code> keyword is, there is an excellent explaination <a href="https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do">here</a>.</p>
<p>Run this spider using the shell command :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scrapy crawl google
</code></pre></div></div>
<p>where <code class="highlighter-rouge">google</code> is the <code class="highlighter-rouge">name</code> of the spider we created.</p>
<h2 id="read-next">Read next</h2>
<p>The <a href="https://doc.scrapy.org/en/latest/">scrapy doc</a> is well written so you can tackle it without apprehension. There is a spider subclass called <a href="https://doc.scrapy.org/en/latest/topics/spiders.html#crawlspider">CrawlSpider</a> that will perform some kind of link filtering for you.</p>
</div>
    </article>
    </div><!-- row -->
    
    <div class="row mt-1">
      <article class="col-lg-8 mx-auto recommendations">
        <p class='title'>Other articles you might like:</p>
        <ul>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/crafting-a-better-search.html">Crafting a better download tool</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/scraping-python-urllib.html">Scraping basics with python3 and urllib</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/propositional-logic-from-probability-calculus.html">Propositional logic derived as a special case of probability calculus</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/win-extend-screen.html">Keyboard shortcut and command line utility to switch display (Windows)</a></li>
          
        </ul>
      </article>
    </div>
    
    
    <div class="row mb=5 mt-5">
      <article class="col-lg-8 mx-auto">
        <div id="hyvor-talk-view"></div>
        <script type="text/javascript">
            var HYVOR_TALK_WEBSITE = '625';
            var HYVOR_TALK_CONFIG = {
                url: 'scraping-python-scrapy.html',
                id: 'scraping-python-scrapy.html'
            };
        </script>
      </article>
    </div><!-- row -->
    
    <footer class="row">
        <div class="col-lg-8 mx-auto text-center">
          <p><small>
          
            Last updated: 01/14/21 <br/>
          
          
          Copyright &copy; 2021 Julien Harbulot
          </small></p>
        </div>
    </footer>
    </div>

  <script>
  // bootstrap table
  tables = document.getElementsByTagName('table');
  for (i = 0; i < tables.length; i++) {
    tables[i].classList.add('table');
    tables[i].classList.add('table-bordered');
  }

  // Paragraphs that contain only images are marked with custom class for styling
  ps = document.getElementsByTagName('p');
  Array.from(ps).forEach(function(p){
    if (p.getElementsByTagName('img').length > 0 && p.textContent.trim().length == 0) {
        p.classList.add('img-container');
    }
  });
  </script>


    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    <script>
        prev_onload_a = window.onload;
        window.onload = function() {
            if (prev_onload_a) {
                prev_onload_a();
            }
            var navlinks = document.getElementsByClassName("nav-link");
            var i;
            for (i = 0; i < navlinks.length; i++) {
                const target = new URL(navlinks[i].href)
                if (location.pathname == target.pathname) {
                    navlinks[i].classList.add('active')
                }
            }
        }
    </script>    

    

<script async type="text/javascript" src="//talk.hyvor.com/web-api/embed"></script>


    </body>
</html>