<!doctype html>
<html lang="en">
    <head>
    

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-166292985-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-166292985-1');
    </script>
    

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" 
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons"
          rel="stylesheet" crossorigin="anonymous">
    
    <link rel="stylesheet" href="/theme/pygment-github.css">
    <link rel="stylesheet" href="/theme/article.css"> 

    <title>Primer on stochastic convergence</title>
    
    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="/images/favicon/site.webmanifest">
    <link rel="mask-icon" href="/images/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="/images/favicon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    
<!-- Mathjax -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG">
  MathJax.Hub.Config({
    tex2jax: {
    	inlineMath: [ ['$','$'] ],
    	processEscapes: true
    },
	"HTML-CSS": {
		fonts: ["TeX"] 
	}
  });
</script>

    </head>

    <body>
    
    <nav class="navbar navbar-expand-lg navbar-light ">
        <a class="navbar-brand" href="//julienharbulot.com/index.html"><img src="//julienharbulot.com/images/logo.png" width="30" alt=""></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/technical-blog.html">Technical blog</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/maths.html">Maths</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/projects.html">Projects</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/research.html">Research</a>
            </li>
            
            <!--<li class="nav-item">
                <a class="nav-link" href="//julienharbulot.com/about-me.html">About me</a>
            </li>-->
            

<li class="nav-item dropdown">
    <a class="nav-link active dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
        Table of content
    </a>
    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
        <div class="toc"><ul>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#types-of-convergence' title='Types of convergence'>Types of convergence</a>
    <ul>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#convergence-in-distribution' title='Convergence in distribution'>Convergence in distribution</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#convergence-in-probability' title='Convergence in probability'>Convergence in probability</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#difference-between-p-and-d-convergence' title='Difference between p and d convergence'>Difference between p and d convergence</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#bonus-cramer-wold-device' title='Bonus: Cramer-Wold Device'>Bonus: Cramer-Wold Device</a>
    </li>
    </ul>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#fundamental-convergence-theorems' title='Fundamental convergence theorems'>Fundamental convergence theorems</a>
    <ul>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#law-of-large-numbers' title='Law of large numbers'>Law of large numbers</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#central-limit-theorem' title='Central limit theorem'>Central limit theorem</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#weighted-sum-central-limit-theorem' title='Weighted sum central limit theorem'>Weighted sum central limit theorem</a>
    </li>
    </ul>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#new-approximations-from-old-ones' title='New approximations from old ones'>New approximations from old ones</a>
    <ul>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#continuous-mapping-theorem' title='Continuous mapping theorem'>Continuous mapping theorem</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#slutskys-theorem' title='Slutsky’s theorem'>Slutsky’s theorem</a>
    </li>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#the-delta-method' title='The delta method'>The delta method</a>
    </li>
    </ul>
</li>
</ul><div>
    </div>
</li>


            </ul>
        </div>
    </nav>
    
    
    
    <div class="container">
    <div class="row mt-5">
      <div class="col-lg-8 mx-auto"> 
        <h1 class="display-5">Primer on stochastic convergence </h1>
        <div class="text-right">01 Nov 2018</div>
      </div>
    </div>
    <div class="row mt-5">
    <article class="col-lg-8 mx-auto">
    <p>
<script type="math/tex; mode=display">
\def\sa{a}
\def\sb{b}
\def\sc{c}
\def\sd{d}
\def\se{e}
\def\sf{f}
\def\sg{g}
\def\sh{h}
\def\si{i}
\def\sj{j}
\def\sk{k}
\def\sl{l}
\def\sm{m}
\def\sn{n}
\def\so{o}
\def\sp{p}
\def\sq{q}
\def\sr{r}
\def\ss{s}
\def\st{t}
\def\su{u}
\def\sv{v}
\def\sw{w}
\def\sx{x}
\def\sy{y}
\def\sz{z}
\def\va{\vec{a}}
\def\vb{\vec{b}}
\def\vc{\vec{c}}
\def\vd{\vec{d}}
\def\ve{\vec{e}}
\def\vf{\vec{f}}
\def\vg{\vec{g}}
\def\vh{\vec{h}}
\def\vi{\vec{i}}
\def\vj{\vec{j}}
\def\vk{\vec{k}}
\def\vl{\vec{l}}
\def\vm{\vec{m}}
\def\vn{\vec{n}}
\def\vo{\vec{o}}
\def\vp{\vec{p}}
\def\vq{\vec{q}}
\def\vr{\vec{r}}
\def\vs{\vec{s}}
\def\vt{\vec{t}}
\def\vu{\vec{u}}
\def\vv{\vec{v}}
\def\vw{\vec{w}}
\def\vx{\vec{x}}
\def\vy{\vec{y}}
\def\vz{\vec{z}}
\def\ga{\mathfrak{A}}
\def\gb{\mathfrak{B}}
\def\gc{\mathfrak{C}}
\def\gd{\mathfrak{D}}
\def\ge{\mathfrak{E}}
\def\gf{\mathfrak{F}}
\def\gg{\mathfrak{G}}
\def\gh{\mathfrak{H}}
\def\gi{\mathfrak{I}}
\def\gj{\mathfrak{J}}
\def\gk{\mathfrak{K}}
\def\gl{\mathfrak{L}}
\def\gm{\mathfrak{M}}
\def\gn{\mathfrak{N}}
\def\go{\mathfrak{O}}
\def\gp{\mathfrak{P}}
\def\gq{\mathfrak{Q}}
\def\gr{\mathfrak{R}}
\def\gs{\mathfrak{S}}
\def\gt{\mathfrak{T}}
\def\gu{\mathfrak{U}}
\def\gv{\mathfrak{V}}
\def\gw{\mathfrak{W}}
\def\gx{\mathfrak{X}}
\def\gy{\mathfrak{Y}}
\def\gz{\mathfrak{Z}}
\def\ra{A}
\def\rb{B}
\def\rc{C}
\def\rd{D}
\def\re{E}
\def\rf{F}
\def\rg{G}
\def\rh{H}
\def\ri{I}
\def\rj{J}
\def\rk{K}
\def\rl{L}
\def\rm{M}
\def\rn{N}
\def\ro{O}
\def\rp{P}
\def\rq{Q}
\def\rr{R}
\def\rs{S}
\def\rt{T}
\def\ru{U}
\def\rv{V}
\def\rw{W}
\def\rx{X}
\def\ry{Y}
\def\rz{Z}
\def\rva{\vec{A}}
\def\rvb{\vec{B}}
\def\rvc{\vec{C}}
\def\rvd{\vec{D}}
\def\rve{\vec{E}}
\def\rvf{\vec{F}}
\def\rvg{\vec{G}}
\def\rvh{\vec{H}}
\def\rvi{\vec{I}}
\def\rvj{\vec{J}}
\def\rvk{\vec{K}}
\def\rvl{\vec{L}}
\def\rvm{\vec{M}}
\def\rvn{\vec{N}}
\def\rvo{\vec{O}}
\def\rvp{\vec{P}}
\def\rvq{\vec{Q}}
\def\rvr{\vec{R}}
\def\rvs{\vec{S}}
\def\rvt{\vec{T}}
\def\rvu{\vec{U}}
\def\rvv{\vec{V}}
\def\rvw{\vec{W}}
\def\rvx{\vec{X}}
\def\rvy{\vec{Y}}
\def\rvz{\vec{Z}}
\def\seta{A}
\def\setb{B}
\def\setc{C}
\def\setd{D}
\def\sete{E}
\def\setf{F}
\def\setg{G}
\def\seth{H}
\def\seti{I}
\def\setj{J}
\def\setk{K}
\def\setl{L}
\def\setm{M}
\def\setn{N}
\def\seto{O}
\def\setp{P}
\def\setq{Q}
\def\setr{R}
\def\sets{S}
\def\sett{T}
\def\setu{U}
\def\setv{V}
\def\setw{W}
\def\setx{X}
\def\sety{Y}
\def\setz{Z}
\def\fa{a}
\def\fb{b}
\def\fc{c}
\def\fd{d}
\def\fe{e}
\def\ff{f}
\def\fg{g}
\def\fh{h}
\def\fi{i}
\def\fj{j}
\def\fk{k}
\def\fl{l}
\def\fm{m}
\def\fn{n}
\def\fo{o}
\def\fp{p}
\def\fq{q}
\def\fr{r}
\def\fs{s}
\def\ft{t}
\def\fu{u}
\def\fv{v}
\def\fw{w}
\def\fx{x}
\def\fy{y}
\def\fz{z}
\def\fA{A}
\def\fB{B}
\def\fC{C}
\def\fD{D}
\def\fE{E}
\def\fF{F}
\def\fG{G}
\def\fH{H}
\def\fI{I}
\def\fJ{J}
\def\fK{K}
\def\fL{L}
\def\fM{M}
\def\fN{N}
\def\fO{O}
\def\fP{P}
\def\fQ{Q}
\def\fR{R}
\def\fS{S}
\def\fT{T}
\def\fU{U}
\def\fV{V}
\def\fW{W}
\def\fX{X}
\def\fY{Y}
\def\fZ{Z}
\def\ma{A}
\def\mb{B}
\def\mc{C}
\def\md{D}
\def\me{E}
\def\mf{F}
\def\mg{G}
\def\mh{H}
\def\mi{I}
\def\mj{J}
\def\mk{K}
\def\ml{L}
\def\mm{M}
\def\mn{N}
\def\mo{O}
\def\mp{P}
\def\mq{Q}
\def\mr{R}
\def\ms{S}
\def\mt{T}
\def\matu{U}
\def\mv{V}
\def\mw{W}
\def\mx{X}
\def\my{Y}
\def\mz{Z}
\def\loss{\mathcal{L}}
\newcommand{\dkl}[2]{D_{\text{KL}}\mathopen{}\paren{#1\,||\,#2}}
\newcommand{\dataset}{S}
\newcommand{\ndataset}{N}
\newcommand{\idataset}{n}
\newcommand{\inputRV}{\mathcal{X}}
\newcommand{\inputvec}{\vec{x}}
\newcommand{\ninputvec}[1]{\vec{x}_{#1}}
\newcommand{\iinputvec}[1]{x_{#1}}
\newcommand{\niinputvec}[2]{x_{#1, #2}}
\newcommand{\icpnt}{i}
\newcommand{\inputmatrix}{X}
\newcommand{\inputdim}{D}
\newcommand{\outputval}{y}
\newcommand{\ioutputval}[1]{y_{#1}}
\newcommand{\outputvec}{\vec{y}}
\newcommand{\trainset}{S_{\text{train}}}
\newcommand{\testset}{S_{\text{test}}}
\newcommand{\truemodel}{f_{\text{true}}}
\newcommand{\trainedmodel}{f_{\trainset}}
\newcommand{\linmodel}[1]{f_{#1}}
\newcommand{\bestmodel}{f^{*}}
\newcommand{\model}{f}
\newcommand{\hyperparam}{\lambda}
\newcommand{\linparamv}{\vec{w}}
\newcommand{\ilinparam}[1]{w_{#1}}
\newcommand{\indivloss}{l}
\newcommand{\modelclass}{\mathcal{F}}
\newcommand{\linclass}{\modelclass_{\text{lin}}}
\newcommand{\g}{\mathcal{G}}
\newcommand{\gmse}{\g_{\text{MSE}}}
\newcommand{\glasso}{\g_{\text{lasso}}}
\newcommand{\gridge}{\g_{\text{ridge}}}
\newcommand{\glogit}{\g_{\logit}}
\newcommand{\l}{\mathcal{L}}
\newcommand{\lmse}{\l_{\text{MSE}}}
\newcommand{\lmae}{\l_{\text{MAE}}}
\newcommand{\llasso}{\l_{\text{lasso}}}
\newcommand{\lridge}{\l_{\text{ridge}}}
\newcommand{\llogit}{\l_{\logit}}
\newcommand{\logit}{\sigma}
\newcommand{\reg}{\mathcal{R}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\mean}{mean}
\DeclareMathOperator*{\avg}{avg}
\DeclareMathOperator*{\span}{span}
\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\bias}{bias}
\newcommand{\expectation}{\mathbb{E}}
\newcommand{\brak}[1]{\left[#1\right]}
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\realset}{\mathbb{R}}
\newcommand{\realvset}[1]{\realset^{#1}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\gaussian}{\mathcal{N}}
\newcommand{\iid}{\stackrel{\text{i.i.d.}}{\sim}}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\normtwo}[1]{\norm{#1}_{2}}
\newcommand{\normone}[1]{\norm{#1}_{1}}
\newcommand{\card}[1]{\left\lvert#1\right\rvert}
\newcommand{\grad}{\nabla}
\newcommand{\dconv}{\stackrel{d}{\to}}
\newcommand{\pconv}{\stackrel{p}{\to}}
\newcommand{\rva}[1]{#1}
\newcommand{\rve}[1]{\vec{#1}}
\newcommand{\obs}[1]{#1}
\newcommand{\vobs}[1]{\vec{#1}}
\newcommand{\distrib}[1]{#1}
\newcommand{\distribof}[2]{#1_{#2}}
\newcommand{\density}[1]{#1}
\newcommand{\densityof}[2]{#1_{#2}}
\newcommand{\distributed}{\sim}
\newcommand{\const}[1]{#1}
\newcommand{\fun}[1]{#1}
</script>
</p>
<div class="typography">

<h2 id="types-of-convergence">Types of convergence</h2>
<h3 id="convergence-in-distribution">Convergence in distribution</h3>
<div class="defn">
<p>Let <script type="math/tex">(\distrib{F}_n)_{n \geq 1}</script> a sequence of distribution functions and let <script type="math/tex">\distrib{G}</script> a distribution function with same domain. Let <script type="math/tex">\mathcal{C}(\distrib{G})</script> the set of continuity points of <script type="math/tex">\distrib{G}</script>. We say that <script type="math/tex">(\distrib{F}_n)_n</script> converge in distribution to <script type="math/tex">\distrib{G}</script>:</p>
<script type="math/tex; mode=display">\distrib{F}_n \dconv \distrib{G}</script>
<p>When for all continuity point <script type="math/tex">\vobs{y} \in \mathcal{C}(\distrib{G})</script>:</p>
<script type="math/tex; mode=display">\lim_{n \to \infty} \distrib{F}_n(\vobs{y}) \to \distrib{G}(\vobs{y})</script>
</div>
<p>Relation to functional analysis: convergence in distribution is pointwise convergence of the distribution functions on the set of continuity points.</p>
<p>By abuse of notation, we extend this definition to sequence of random variables/vectors <script type="math/tex">(\rve{Y}_n)_{n \geq 1}</script>:</p>
<script type="math/tex; mode=display">\rve{Y}_n \dconv \rve{Y} \iff \distrib{F}_{\rve{Y}_n} \dconv \distrib{F}_{\rve{Y}}</script>
<h3 id="convergence-in-probability">Convergence in probability</h3>
<div class="defn">
<p>Let <script type="math/tex">(\rve{Y}_n)_{n \geq 1}</script> a sequence of random vector. We say that it converges in probability to the random vector <script type="math/tex">\rve{Y}</script>:</p>
<script type="math/tex; mode=display">\rve{Y}_n \pconv \rve{Y}</script>
<p>When for all <script type="math/tex">\epsilon > 0</script> we have:</p>
<script type="math/tex; mode=display">\prob\brak{\norm{\rve{Y}_n - \rve{Y}} > \epsilon} \stackrel{n \to \infty}{\to} 0</script>
</div>
<p>Since a random variable <script type="math/tex">\rva{Y}</script> is a random vector of dimension <script type="math/tex">1</script>, for random variable the condition is writen:</p>
<script type="math/tex; mode=display">\prob\brak{\abs{\rva{Y}_n - \rva{Y}} > \epsilon} \stackrel{n \to \infty}{\to} 0</script>
<h3 id="difference-between-p-and-d-convergence">Difference between p and d convergence</h3>
<ul>
<li><script type="math/tex">d</script>-convergence relates distribution functions. It says the probabilistic behavior of a sequence <script type="math/tex">\rva{Y}_n</script> becomes more and more alike to that of the limit <script type="math/tex">\rva{Y}</script>.</li>
<li>
<p><script type="math/tex">p</script>-convergence relates random variables. It says the actual realisations of <script type="math/tex">\rva{Y}_n</script> can be progressively approximated with high probability by those of <script type="math/tex">\rva{Y}</script>.</p>
</li>
<li><script type="math/tex">p</script>-convergence implies <script type="math/tex">d</script>-convergence.</li>
<li><script type="math/tex">d</script>-convergence does not imply <script type="math/tex">p</script>-convergence.</li>
</ul>
<p>Example: let <script type="math/tex">\rva{Z} \distributed \gaussian(0, 1)</script>. We have:</p>
<table>
<tbody>
<tr>
<td> </td>
<td><script type="math/tex">\paren{\frac{1}{n} - Z} \dconv Z</script></td>
<td>but</td>
<td><script type="math/tex">\paren{\frac{1}{n} - Z} \pconv -Z</script></td>
</tr>
</tbody>
</table>
<p>There is a partial converse when the limit is a constant <script type="math/tex">c \in \realset</script>:</p>
<script type="math/tex; mode=display">\rva{Y}_n \dconv \const{c} \implies \rva{Y}_n \pconv \const{c}</script>
<h3 id="bonus-cramer-wold-device">Bonus: Cramer-Wold Device</h3>
<p>As a side note, there is a link between univariate and multivariate <script type="math/tex">d</script>-convergence:</p>
<div class="thm">
<p>Let <script type="math/tex">\rve{Y}_n</script> be a sequence of random vectors of <script type="math/tex">\realvset{d}</script> and <script type="math/tex">\rve{Y}</script> a random vector. For any constant vector <script type="math/tex">\vec{u} \in \realvset{d}</script>, the random variable <script type="math/tex">(\vec{u} \cdot Y_n)</script> is univariate. We have:</p>
<script type="math/tex; mode=display">\rve{Y}_n \dconv \rve{Y} \iff \forall \vec{u} \in \realvset{d}, \, \vec{u}\cdot\rve{Y}_n \dconv \vec{u}\cdot\rve{Y}</script>
</div>
<h2 id="fundamental-convergence-theorems">Fundamental convergence theorems</h2>
<h3 id="law-of-large-numbers">Law of large numbers</h3>
<div class="thm">
<p>Let <script type="math/tex">(\rve{Y}_k)_{k\geq 1}</script> be a sequence of indepent random vectors with <script type="math/tex">\expectation\brak{\rve{Y}_k} = \vec{\mu}</script> and <script type="math/tex">% <![CDATA[
\expectation\norm{\rve{Y}_k} < \infty %]]></script> for all <script type="math/tex">n \geq 1</script>. Then:</p>
<script type="math/tex; mode=display">\paren{\frac{1}{n}\sum_{k = 1}^{n} \rve{Y}_k} \pconv \vec{\mu}</script>
</div>
<p>Interpretation: since it is <script type="math/tex">p</script>-convergence, this means that as the sample size <script type="math/tex">n</script> increases, there is higher and higher probability that the value of the sample average: <script type="math/tex">\avg\{\rve{Y}_k \mid k \leq n\}</script> is a good approximation to the mean <script type="math/tex">\vec{\mu}</script>.</p>
<p>But what is the uncertainty associated with this approximation? Under slightly stronger assumptions on the sequence, the following theorem is the answer.</p>
<h3 id="central-limit-theorem">Central limit theorem</h3>
<div class="thm">
<p>Let <script type="math/tex">(\rve{Y}_k)_{k \geq 1}</script> be an i.i.d. sequence of random vectors with mean <script type="math/tex">\vec{\mu}</script> and covariance matrix <script type="math/tex">\Omega</script>. Then:</p>
<script type="math/tex; mode=display">\sqrt{n} \cdot \paren{\frac{1}{n}\sum_{k = 1}^{n} \rve{Y}_k} \dconv \gaussian_d\paren{\vec{\mu}, \Omega}</script>
</div>
<p>When the dimension is <script type="math/tex">1</script>, the covariance matrix reduces to the variance <script type="math/tex">\sigma^2</script> and the theorem reads:</p>
<div class="thm">
<p>Let <script type="math/tex">(\rva{Y}_k)_{k \geq 1}</script> be an i.i.d. sequence with mean <script type="math/tex">\mu</script> and variance <script type="math/tex">% <![CDATA[
\sigma^2 < \infty %]]></script>. Then:</p>
<script type="math/tex; mode=display">\sqrt{n} \cdot \paren{\frac{1}{n}\sum_{k = 1}^{n} \rva{Y}_k} \dconv \gaussian\paren{\mu, \sigma^2}</script>
</div>
<p>Interpretation: as the sample size <script type="math/tex">n</script> increases, the distribution of the sample average is a normal distribution with mean <script type="math/tex">\mu</script> and standard deviation <script type="math/tex">\frac{\sigma}{\sqrt{n}}</script>:</p>
<script type="math/tex; mode=display">\paren{\frac{1}{n}\sum_{k = 1}^{n} \rva{Y}_k} \approx \gaussian\paren{\mu, \frac{\sigma^2}{n}}</script>
<p>Notice that the standard deviation shrinks at the speed of <script type="math/tex">\frac{1}{\sqrt{n}}</script>.</p>
<h3 id="weighted-sum-central-limit-theorem">Weighted sum central limit theorem</h3>
<p>A more general version of the CLT is often useful when combined with the tools presented in the next section.</p>
<div class="thm">
<p>Let <script type="math/tex">(\rva{Y}_k)_{k \geq 1}</script> be an i.i.d. sequence of real random variables with common mean <script type="math/tex">\expectation\brak{\rva{Y}_k} = 0</script> and variance <script type="math/tex">\sigma^2 = 1</script>. Let <script type="math/tex">(a_i)_{i \geq 1}</script> be a sequence of real constants.</p>
<p>Use the following notations: <script type="math/tex">\vec{a}_{n} = (a_1, \dotsc, a_n)</script>, and <script type="math/tex">\rve{Y}_{n} = (\rva{Y}_1, \dotsc, \rva{Y}_n)</script>.</p>
<p>If, in the limit, any single component contributes a negligible proportion of the total variance, i.e:</p>
<script type="math/tex; mode=display">\sup_{1 \leq i \leq n} \frac{a_i^2}{\norm{\vec{a}_{n}}} \stackrel{n \to \infty}{\to} 0</script>
<p>Then:</p>
<script type="math/tex; mode=display">\frac{\vec{a_{n}} \cdot \rve{Y}_{n}}{\norm{\vec{a}_{n}}} \,\dconv\,\gaussian(0, 1)</script>
</div>
<p>Setting <script type="math/tex">a_i = 1</script> for all <script type="math/tex">i</script> yields the previous univariate central limit theorem.</p>
<h2 id="new-approximations-from-old-ones">New approximations from old ones</h2>
<p>These theorems are used to approximate complicated distributions by simpler ones. Here are some transformation results that let us obtain new approximations from the old ones.</p>
<h3 id="continuous-mapping-theorem">Continuous mapping theorem</h3>
<div class="thm">
<p>Let <script type="math/tex">\fun{g}: \realset \to \realset</script> be a continuous function. Then:</p>
<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
& \rva{Y}_n \pconv \rva{Y} \implies \fun{g}(\rva{Y}_n) \pconv \fun{g}(\rva{Y}) \\
& \rva{Y}_n \dconv \rva{Y} \implies \fun{g}(\rva{Y}_n) \dconv \fun{g}(\rva{Y})
\end{align*} %]]></script>
</div>
<h3 id="slutskys-theorem">Slutsky’s theorem</h3>
<div class="thm">
<p>Let <script type="math/tex">\fun{g}: \realset \times \realset \to \realset</script> be a continuous function and <script type="math/tex">(\rva{Y}_n)_n</script>, <script type="math/tex">(\rva{X}_n)_n</script> two sequences of random variables and <script type="math/tex">c \in \realset</script> a constant. Then:</p>
<script type="math/tex; mode=display">% <![CDATA[
\begin{cases} \rva{X}_n &\dconv \rva{X} \\ \rva{Y}_n &\dconv \const{c} \end{cases} \implies \fun{g}\paren{\rva{X}_n, \rva{Y}_n} \dconv \fun{g}\paren{\rva{X}, c} %]]></script>
</div>
<p>The continuous mapping theorem would be applicable if the joint-distribution of <script type="math/tex">\rve{Z}_n = (\rva{X}_n, \rva{Y}_n)</script> <script type="math/tex">d</script>-converged to that of <script type="math/tex">\rve{Z} = (\rva{X}, c)</script>. But Slutsky’s theorem is a stronger result because we only assume marginal convergence.</p>
<h3 id="the-delta-method">The delta method</h3>
<div class="thm">
<p>Let <script type="math/tex">\rve{Z}_n = a_n\,(\rve{X}_n - \vec{u}) \dconv \rve{Z}</script> where <script type="math/tex">\vec{u} \in \realvset{d}</script>, <script type="math/tex">a_n \in \realset</script> and <script type="math/tex">a_n \to \infty</script>. Let <script type="math/tex">\fun{g}: \realvset{d} \to \realvset{p}</script> be continuously differentiable at point <script type="math/tex">\vec{u}</script>. Then:</p>
<script type="math/tex; mode=display">a_n\,(\fun{g(\rve{X}) - g(\vec{u})}) \dconv \frac{\partial}{\partial \vec{u}}\fun{g}(\vec{u})\cdot\rve{Z}</script>
</div>
<p>Where <script type="math/tex">\frac{\partial}{\partial \vec{u}}\fun{g}(\vec{u})</script> is the <a class="def" href="derivatives.html">derivative</a> of <script type="math/tex">\fun{g}</script> at point <script type="math/tex">\vec{u}</script>. When the dimension is <script type="math/tex">1</script>, this is the usual <a class="def" href="derivatives.html">derivative</a> <script type="math/tex">\fun{g}'(u)</script>, otherwise this is the <a class="def" href="derivatives.html">jacobian</a> matrix.</p>
</div>
    </article>
    </div><!-- row -->
    
    <div class="row mt-1">
      <article class="col-lg-8 mx-auto recommendations">
        <p class='title'>Other articles you might like:</p>
        <ul>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/residuals.html">What is a residual?</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/design-matrix.html">What is the design matrix?</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/scraping-python-urllib.html">Scraping basics with python3 and urllib</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/win-extend-screen.html">Keyboard shortcut and command line utility to switch display (Windows)</a></li>
          
        </ul>
      </article>
    </div>
    
    
    <div class="row mb=5 mt-5">
      <article class="col-lg-8 mx-auto">
        <div id="hyvor-talk-view"></div>
        <script type="text/javascript">
            var HYVOR_TALK_WEBSITE = '625';
            var HYVOR_TALK_CONFIG = {
                url: 'stochastic-convergence.html',
                id: 'stochastic-convergence.html'
            };
        </script>
      </article>
    </div><!-- row -->
    
    <footer class="row">
        <div class="col-lg-8 mx-auto text-center">
          <p><small>
          
            Last updated: 01/14/21 <br/>
          
          
          Copyright &copy; 2021 Julien Harbulot
          </small></p>
        </div>
    </footer>
    </div>

  <script>
  // bootstrap table
  tables = document.getElementsByTagName('table');
  for (i = 0; i < tables.length; i++) {
    tables[i].classList.add('table');
    tables[i].classList.add('table-bordered');
  }

  // Paragraphs that contain only images are marked with custom class for styling
  ps = document.getElementsByTagName('p');
  Array.from(ps).forEach(function(p){
    if (p.getElementsByTagName('img').length > 0 && p.textContent.trim().length == 0) {
        p.classList.add('img-container');
    }
  });
  </script>


    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    <script>
        prev_onload_a = window.onload;
        window.onload = function() {
            if (prev_onload_a) {
                prev_onload_a();
            }
            var navlinks = document.getElementsByClassName("nav-link");
            var i;
            for (i = 0; i < navlinks.length; i++) {
                const target = new URL(navlinks[i].href)
                if (location.pathname == target.pathname) {
                    navlinks[i].classList.add('active')
                }
            }
        }
    </script>    

    

<script async type="text/javascript" src="//talk.hyvor.com/web-api/embed"></script>


    </body>
</html>