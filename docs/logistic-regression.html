<!doctype html>
<html lang="en">
    <head>
    

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-166292985-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-166292985-1');
    </script>
    

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" 
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons"
          rel="stylesheet" crossorigin="anonymous">
    
    <link rel="stylesheet" href="/theme/pygment-github.css">
    <link rel="stylesheet" href="/theme/article.css"> 

    <title>What is logistic regression?</title>
    
    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="/images/favicon/site.webmanifest">
    <link rel="mask-icon" href="/images/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="/images/favicon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    
<!-- Mathjax -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG">
  MathJax.Hub.Config({
    tex2jax: {
    	inlineMath: [ ['$','$'] ],
    	processEscapes: true
    },
	"HTML-CSS": {
		fonts: ["TeX"] 
	}
  });
</script>

    </head>

    <body>
    
    <nav class="navbar navbar-expand-lg navbar-dark" style="background-color: rgb(78, 76, 103);">
        <a class="navbar-brand" href="//julienharbulot.com/index.html"><img src="//julienharbulot.com/images/logo.svg" width="30" alt=""></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/technical-blog.html">Technical blog</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/maths.html">Maths</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/research.html">Research</a>
            </li>
            
            <li class="nav-item">
                    <a class="nav-link" href="//julienharbulot.com/projects.html">Projects</a>
            </li>
            
            <!--<li class="nav-item">
                <a class="nav-link" href="//julienharbulot.com/about-me.html">About me</a>
            </li>-->
            

<li class="nav-item dropdown">
    <a class="nav-link active dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
        Table of content
    </a>
    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
        <div class="toc"><ul>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#setup' title='Setup'>Setup</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#generalized-linear-models' title='Generalized Linear models'>Generalized Linear models</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#the-inverse-link-function' title='The inverse link function'>The inverse link function</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#the-logistic-loss' title='The logistic loss'>The logistic loss</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#origin-of-the-logistic-loss' title='Origin of the logistic loss'>Origin of the logistic loss</a>
    <ul>
<li class="toc-entry-2">
    <a class='toc-href dropdown-item' href='#learning-the-models-parameters' title='Learning the model’s parameters'>Learning the model’s parameters</a>
    </li>
    </ul>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#logistic-regression-is-a-generalized-linear-model' title='Logistic regression is a generalized linear model'>Logistic regression is a generalized linear model</a>
</li>
<div class="dropdown-divider"></div>
<li class="toc-entry-1">
<a class='toc-href dropdown-item' href='#underlying-probabilistic-model' title='Underlying probabilistic model'>Underlying probabilistic model</a>
</li>
</ul><div>
    </div>
</li>


            </ul>
        </div>
    </nav>
    
    
    
    <div class="container">
    <div class="row mt-5">
      <div class="col-lg-8 mx-auto"> 
        <h1 class="display-5">What is logistic regression? </h1>
        <div class="text-right">26 Oct 2018</div>
      </div>
    </div>
    <div class="row mt-5">
    <article class="col-lg-8 mx-auto">
    <p>
<script type="math/tex; mode=display">
\def\sa{a}
\def\sb{b}
\def\sc{c}
\def\sd{d}
\def\se{e}
\def\sf{f}
\def\sg{g}
\def\sh{h}
\def\si{i}
\def\sj{j}
\def\sk{k}
\def\sl{l}
\def\sm{m}
\def\sn{n}
\def\so{o}
\def\sp{p}
\def\sq{q}
\def\sr{r}
\def\ss{s}
\def\st{t}
\def\su{u}
\def\sv{v}
\def\sw{w}
\def\sx{x}
\def\sy{y}
\def\sz{z}
\def\va{\vec{a}}
\def\vb{\vec{b}}
\def\vc{\vec{c}}
\def\vd{\vec{d}}
\def\ve{\vec{e}}
\def\vf{\vec{f}}
\def\vg{\vec{g}}
\def\vh{\vec{h}}
\def\vi{\vec{i}}
\def\vj{\vec{j}}
\def\vk{\vec{k}}
\def\vl{\vec{l}}
\def\vm{\vec{m}}
\def\vn{\vec{n}}
\def\vo{\vec{o}}
\def\vp{\vec{p}}
\def\vq{\vec{q}}
\def\vr{\vec{r}}
\def\vs{\vec{s}}
\def\vt{\vec{t}}
\def\vu{\vec{u}}
\def\vv{\vec{v}}
\def\vw{\vec{w}}
\def\vx{\vec{x}}
\def\vy{\vec{y}}
\def\vz{\vec{z}}
\def\ga{\mathfrak{A}}
\def\gb{\mathfrak{B}}
\def\gc{\mathfrak{C}}
\def\gd{\mathfrak{D}}
\def\ge{\mathfrak{E}}
\def\gf{\mathfrak{F}}
\def\gg{\mathfrak{G}}
\def\gh{\mathfrak{H}}
\def\gi{\mathfrak{I}}
\def\gj{\mathfrak{J}}
\def\gk{\mathfrak{K}}
\def\gl{\mathfrak{L}}
\def\gm{\mathfrak{M}}
\def\gn{\mathfrak{N}}
\def\go{\mathfrak{O}}
\def\gp{\mathfrak{P}}
\def\gq{\mathfrak{Q}}
\def\gr{\mathfrak{R}}
\def\gs{\mathfrak{S}}
\def\gt{\mathfrak{T}}
\def\gu{\mathfrak{U}}
\def\gv{\mathfrak{V}}
\def\gw{\mathfrak{W}}
\def\gx{\mathfrak{X}}
\def\gy{\mathfrak{Y}}
\def\gz{\mathfrak{Z}}
\def\ra{A}
\def\rb{B}
\def\rc{C}
\def\rd{D}
\def\re{E}
\def\rf{F}
\def\rg{G}
\def\rh{H}
\def\ri{I}
\def\rj{J}
\def\rk{K}
\def\rl{L}
\def\rm{M}
\def\rn{N}
\def\ro{O}
\def\rp{P}
\def\rq{Q}
\def\rr{R}
\def\rs{S}
\def\rt{T}
\def\ru{U}
\def\rv{V}
\def\rw{W}
\def\rx{X}
\def\ry{Y}
\def\rz{Z}
\def\rva{\vec{A}}
\def\rvb{\vec{B}}
\def\rvc{\vec{C}}
\def\rvd{\vec{D}}
\def\rve{\vec{E}}
\def\rvf{\vec{F}}
\def\rvg{\vec{G}}
\def\rvh{\vec{H}}
\def\rvi{\vec{I}}
\def\rvj{\vec{J}}
\def\rvk{\vec{K}}
\def\rvl{\vec{L}}
\def\rvm{\vec{M}}
\def\rvn{\vec{N}}
\def\rvo{\vec{O}}
\def\rvp{\vec{P}}
\def\rvq{\vec{Q}}
\def\rvr{\vec{R}}
\def\rvs{\vec{S}}
\def\rvt{\vec{T}}
\def\rvu{\vec{U}}
\def\rvv{\vec{V}}
\def\rvw{\vec{W}}
\def\rvx{\vec{X}}
\def\rvy{\vec{Y}}
\def\rvz{\vec{Z}}
\def\seta{A}
\def\setb{B}
\def\setc{C}
\def\setd{D}
\def\sete{E}
\def\setf{F}
\def\setg{G}
\def\seth{H}
\def\seti{I}
\def\setj{J}
\def\setk{K}
\def\setl{L}
\def\setm{M}
\def\setn{N}
\def\seto{O}
\def\setp{P}
\def\setq{Q}
\def\setr{R}
\def\sets{S}
\def\sett{T}
\def\setu{U}
\def\setv{V}
\def\setw{W}
\def\setx{X}
\def\sety{Y}
\def\setz{Z}
\def\fa{a}
\def\fb{b}
\def\fc{c}
\def\fd{d}
\def\fe{e}
\def\ff{f}
\def\fg{g}
\def\fh{h}
\def\fi{i}
\def\fj{j}
\def\fk{k}
\def\fl{l}
\def\fm{m}
\def\fn{n}
\def\fo{o}
\def\fp{p}
\def\fq{q}
\def\fr{r}
\def\fs{s}
\def\ft{t}
\def\fu{u}
\def\fv{v}
\def\fw{w}
\def\fx{x}
\def\fy{y}
\def\fz{z}
\def\fA{A}
\def\fB{B}
\def\fC{C}
\def\fD{D}
\def\fE{E}
\def\fF{F}
\def\fG{G}
\def\fH{H}
\def\fI{I}
\def\fJ{J}
\def\fK{K}
\def\fL{L}
\def\fM{M}
\def\fN{N}
\def\fO{O}
\def\fP{P}
\def\fQ{Q}
\def\fR{R}
\def\fS{S}
\def\fT{T}
\def\fU{U}
\def\fV{V}
\def\fW{W}
\def\fX{X}
\def\fY{Y}
\def\fZ{Z}
\def\ma{A}
\def\mb{B}
\def\mc{C}
\def\md{D}
\def\me{E}
\def\mf{F}
\def\mg{G}
\def\mh{H}
\def\mi{I}
\def\mj{J}
\def\mk{K}
\def\ml{L}
\def\mm{M}
\def\mn{N}
\def\mo{O}
\def\mp{P}
\def\mq{Q}
\def\mr{R}
\def\ms{S}
\def\mt{T}
\def\matu{U}
\def\mv{V}
\def\mw{W}
\def\mx{X}
\def\my{Y}
\def\mz{Z}
\def\loss{\mathcal{L}}
\newcommand{\dkl}[2]{D_{\text{KL}}\mathopen{}\paren{#1\,||\,#2}}
\newcommand{\dataset}{S}
\newcommand{\ndataset}{N}
\newcommand{\idataset}{n}
\newcommand{\inputRV}{\mathcal{X}}
\newcommand{\inputvec}{\vec{x}}
\newcommand{\ninputvec}[1]{\vec{x}_{#1}}
\newcommand{\iinputvec}[1]{x_{#1}}
\newcommand{\niinputvec}[2]{x_{#1, #2}}
\newcommand{\icpnt}{i}
\newcommand{\inputmatrix}{X}
\newcommand{\inputdim}{D}
\newcommand{\outputval}{y}
\newcommand{\ioutputval}[1]{y_{#1}}
\newcommand{\outputvec}{\vec{y}}
\newcommand{\trainset}{S_{\text{train}}}
\newcommand{\testset}{S_{\text{test}}}
\newcommand{\truemodel}{f_{\text{true}}}
\newcommand{\trainedmodel}{f_{\trainset}}
\newcommand{\linmodel}[1]{f_{#1}}
\newcommand{\bestmodel}{f^{*}}
\newcommand{\model}{f}
\newcommand{\hyperparam}{\lambda}
\newcommand{\linparamv}{\vec{w}}
\newcommand{\ilinparam}[1]{w_{#1}}
\newcommand{\indivloss}{l}
\newcommand{\modelclass}{\mathcal{F}}
\newcommand{\linclass}{\modelclass_{\text{lin}}}
\newcommand{\g}{\mathcal{G}}
\newcommand{\gmse}{\g_{\text{MSE}}}
\newcommand{\glasso}{\g_{\text{lasso}}}
\newcommand{\gridge}{\g_{\text{ridge}}}
\newcommand{\glogit}{\g_{\logit}}
\newcommand{\l}{\mathcal{L}}
\newcommand{\lmse}{\l_{\text{MSE}}}
\newcommand{\lmae}{\l_{\text{MAE}}}
\newcommand{\llasso}{\l_{\text{lasso}}}
\newcommand{\lridge}{\l_{\text{ridge}}}
\newcommand{\llogit}{\l_{\logit}}
\newcommand{\logit}{\sigma}
\newcommand{\reg}{\mathcal{R}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\mean}{mean}
\DeclareMathOperator*{\avg}{avg}
\DeclareMathOperator*{\span}{span}
\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\bias}{bias}
\newcommand{\expectation}{\mathbb{E}}
\newcommand{\brak}[1]{\left[#1\right]}
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\realset}{\mathbb{R}}
\newcommand{\realvset}[1]{\realset^{#1}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\gaussian}{\mathcal{N}}
\newcommand{\iid}{\stackrel{\text{i.i.d.}}{\sim}}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\normtwo}[1]{\norm{#1}_{2}}
\newcommand{\normone}[1]{\norm{#1}_{1}}
\newcommand{\card}[1]{\left\lvert#1\right\rvert}
\newcommand{\grad}{\nabla}
\newcommand{\dconv}{\stackrel{d}{\to}}
\newcommand{\pconv}{\stackrel{p}{\to}}
\newcommand{\rva}[1]{#1}
\newcommand{\rve}[1]{\vec{#1}}
\newcommand{\obs}[1]{#1}
\newcommand{\vobs}[1]{\vec{#1}}
\newcommand{\distrib}[1]{#1}
\newcommand{\distribof}[2]{#1_{#2}}
\newcommand{\density}[1]{#1}
\newcommand{\densityof}[2]{#1_{#2}}
\newcommand{\distributed}{\sim}
\newcommand{\const}[1]{#1}
\newcommand{\fun}[1]{#1}
</script>
</p>
<div class="typography">

<p>A Logistic regression is a <a class="def" href="generalized-linear-models.html">generalized linear model</a> which is tailored to <a class="def" href="classification-vs-regression.html">classification</a>. In this article, we introduce this regression and explain its origin.</p>
<h2 id="setup">Setup</h2>
<p>The dataset <script type="math/tex">\dataset</script> of study consists of <script type="math/tex">\ndataset</script> pairs of input vector <script type="math/tex">\inputvec_{\idataset}</script> and output value <script type="math/tex">\outputval_{\idataset}</script>:</p>
<script type="math/tex; mode=display">\dataset = \{\paren{\inputvec_{\idataset}, \outputval_{\idataset}} \mid \idataset \leq \ndataset\}</script>
<p>We suppose that there exists an approximate deterministic relationship <script type="math/tex">\truemodel</script> between the inputs <script type="math/tex">\inputvec_{\idataset}</script> and the outputs <script type="math/tex">\outputval_{\idataset}</script>:</p>
<script type="math/tex; mode=display">\forall \idataset \leq \ndataset, \quad \outputval_{\idataset} \approx \truemodel\paren{\inputvec_{\idataset}}</script>
<p>The goal of a logistic regression is to learn this relationship using a subset <script type="math/tex">\trainset \subseteq \dataset</script> of the dataset.</p>
<h2 id="generalized-linear-models">Generalized Linear models</h2>
<p>We will approximate the relationship <script type="math/tex">\truemodel</script> using the combination of a deterministic function <script type="math/tex">\logit</script> and a linear model. This means that we want to find the best model <script type="math/tex">\bestmodel</script> in the <a href="#">class <script type="math/tex">\linclass</script> of linear models</a> such that:</p>
<script type="math/tex; mode=display">\logit\circ\bestmodel(\ninputvec{\idataset}) = \logit\paren{\bestmodel(\ninputvec{\idataset})} = \truemodel(\ninputvec{\idataset})</script>
<h2 id="the-inverse-link-function">The inverse link function</h2>
<p>The deterministic function <script type="math/tex">\logit</script> that we will use is the logistic function (we will explain why later):</p>
<script type="math/tex; mode=display">\logit(x) = \frac{e^x}{1 + e^x}</script>
<p>Here is a graph of this function:</p>
<p><img alt="Logistic function" src="images/logistic-regression/logistic_curve.png"/></p>
<h2 id="the-logistic-loss">The logistic loss</h2>
<p>To measure progress during learning, we use the logistic loss:</p>
<script type="math/tex; mode=display">\begin{align*}
\llogit(\linmodel{\linparamv}, \dataset) = - \sum_{\idataset = 1}^{\ndataset} \, \ln\paren{1 + e^{\linmodel{\linparamv}(\ninputvec{\idataset})}} - \ioutputval{\idataset}\,\linmodel{\linparamv}(\ninputvec{\idataset})
\end{align*}</script>
<p>Learning the best model then amounts to minimizing the training objective <script type="math/tex">\g</script></p>
<h2 id="origin-of-the-logistic-loss">Origin of the logistic loss</h2>
<p>As discussed <a href="classification-vs-regression.html">in this article</a>, usual regression models are ill-adapted to <a class="def" href="classification-vs-regression.html">classification</a>.</p>
<p>Logistic regression, however, is tailored to <a class="def" href="classification-vs-regression.html">classification</a> problems: instead of directly attempting to predict the <a class="def" href="target-variable.html">label</a> <script type="math/tex">\outputval \in \{0, 1\}</script>, predict the probability <script type="math/tex">p(1 \mid \inputvec)</script> that <script type="math/tex">\inputvec</script> is in class <script type="math/tex">1</script>. That way, we turn a discrete <a class="def" href="classification-vs-regression.html">classification</a> problem into a continuous regression problem.</p>
<p>Since the values predicted by a regression model are in range <script type="math/tex">]-\infty;+\infty[</script>, there only remains to find a way to continuously shrink this range to <script type="math/tex">[0; 1]</script>. This can be done using the logistic function <script type="math/tex">\logit</script>, which is particularly interesting because most of the values it takes agglutinate around <script type="math/tex">0</script> and <script type="math/tex">1</script>:</p>
<script type="math/tex; mode=display">\logit(x) = \frac{e^x}{1 + e^x}</script>
<p>Here is a graph of this function:</p>
<p><img alt="Logistic function" src="images/logistic-regression/logistic_curve.png"/></p>
<p>Using the logistic function, we get the following expression for the probablity <script type="math/tex">p(1 \mid \inputvec)</script> that <script type="math/tex">\inputvec</script> is in class <script type="math/tex">1</script>:</p>
<script type="math/tex; mode=display">p(1 \mid \inputvec) = \logit\paren{\linmodel{\linparamv}\cdot\inputvec}</script>
<p>And the probability <script type="math/tex">p(0 \mid \inputvec)</script> that <script type="math/tex">\inputvec</script> is in class <script type="math/tex">0</script>:</p>
<script type="math/tex; mode=display">p(0 \mid \inputvec) = 1 - \logit\paren{\linmodel{\linparamv}\cdot\inputvec}</script>
<p>To predict the <a class="def" href="target-variable.html">labels</a>, we compare those probabilities to a threshold (<script type="math/tex">0.5</script>):</p>
<script type="math/tex; mode=display">\hat{\ioutputval{\idataset}} = 1 \iff p(1 \mid \ninputvec{\idataset}) > 0.5</script>
<h3 id="learning-the-models-parameters">Learning the model’s parameters</h3>
<p>So, our model predicts the probability <script type="math/tex">p(1 \mid \inputvec)</script> that <script type="math/tex">\inputvec</script> falls within class <script type="math/tex">1</script>. How do we learn its parameter vector <script type="math/tex">\linparamv</script>?</p>
<p>We will maximize the likelihood to obtain our data. Assuming that each training example <script type="math/tex">(\ninputvec{\idataset}, \ioutputval{\idataset})</script> was drawn independently from the distribution <script type="math/tex">p</script>, the joint likelihood is:</p>
<script type="math/tex; mode=display">p(\outputvec, \inputmatrix \mid \linparamv) = \prod_{\idataset = 1}^{\ndataset} p(\ioutputval{\idataset}, \ninputvec{\idataset} \mid \linparamv)</script>
<p>Which is maximal when the log-likelihood is:</p>
<script type="math/tex; mode=display">\ln\circ\, p(\outputvec, \inputmatrix \mid \linparamv) = \sum_{\idataset = 1}^{\ndataset} \ln\circ\, p(\ioutputval{\idataset}, \ninputvec{\idataset} \mid \linparamv)</script>
<p>Where I use the notation <script type="math/tex">f \circ g(x) = f(g(x))</script> for function composition.</p>
<p>For each <script type="math/tex">\idataset \leq \ndataset</script>, we have:</p>
<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
p(\ioutputval{\idataset}, \ninputvec{\idataset} \mid \linparamv) &= p(\ioutputval{\idataset} \mid \ninputvec{\idataset}, \linparamv)\,p(\ninputvec{\idataset} \mid \linparamv)
\end{align*} %]]></script>
<p>Since:</p>
<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
& \ioutputval{\idataset} = 1 \implies p(\ioutputval{\idataset} \mid \ninputvec{\idataset}, \linparamv) =  \logit\paren{\linmodel{\linparamv}\cdot\ninputvec{\idataset}} \\
& \ioutputval{\idataset} = 0 \implies p(\ioutputval{\idataset} \mid \ninputvec{\idataset}, \linparamv) =  1 - \logit\paren{\linmodel{\linparamv}\cdot\ninputvec{\idataset}}
\end{align*} %]]></script>
<p>We find that:</p>
<script type="math/tex; mode=display">\frac{p(\ioutputval{\idataset} \mid \ninputvec{\idataset}, \linparamv)}{p(\ninputvec{\idataset} \mid \linparamv)} = \ioutputval{\idataset}\,\logit\paren{\linmodel{\linparamv}\cdot\ninputvec{\idataset}} + \paren{1 - \ioutputval{\idataset}}\,\paren{1 - \logit\paren{\linmodel{\linparamv}\cdot\ninputvec{\idataset}}}</script>
<p>Since <script type="math/tex">p(\ninputvec{\idataset} \mid \linparamv)</script> is a constant (the inputs does not depend on <script type="math/tex">\linparamv</script>), we find that the value to maximize is:</p>
<script type="math/tex; mode=display">\sum_{\idataset = 1}^{\ndataset}  \ioutputval{\idataset}\,\ln\circ\, \logit\paren{\linmodel{\linparamv}\cdot\ninputvec{\idataset}} + \paren{1 - \ioutputval{\idataset}}\,\paren{1 - \ln\circ\, \logit\paren{\linmodel{\linparamv}\cdot\ninputvec{\idataset}}}</script>
<p>Replacing <script type="math/tex">\logit</script> by its definition and simplifying, we find the expression to maximize:</p>
<script type="math/tex; mode=display">\sum_{\idataset = 1}^{\ndataset} \, \ln\paren{1 + e^{\linmodel{\linparamv}(\ninputvec{\idataset})}} - \ioutputval{\idataset}\,\linmodel{\linparamv}(\ninputvec{\idataset})</script>
<p>Which is precisely <script type="math/tex">- \llogit(\linmodel{\linparamv}, \dataset)</script>. Hence its use as loss function.</p>
<p>But…</p>
<p>The choice of <script type="math/tex">\logit</script> might seem arbitrary. Is it a good idea to predict the probability <script type="math/tex">p(1 \mid \inputvec)</script>? What if we used another function to shrink <script type="math/tex">]-\infty;+\infty[</script>?</p>
<p>The theoretical soundness of the logistic regression is explained in the following section.</p>
<h2 id="logistic-regression-is-a-generalized-linear-model">Logistic regression is a generalized linear model</h2>
<p>Logistic regression is a <a class="def" href="generalized-linear-models.html">generalized linear model</a> with inverse link function:</p>
<script type="math/tex; mode=display">\logit(x) = \frac{e^x}{1 + e^x}</script>
<p>The output <script type="math/tex">\linmodel{\linparamv}(\inputvec)</script> of the linear regression is an estimate of the natural parameter <script type="math/tex">\eta</script> of a Bernoulli(<script type="math/tex">p</script>) distribution:</p>
<script type="math/tex; mode=display">\eta = \logit^{-1}(p) = \ln\paren{\frac{p}{1 - p}}</script>
<h2 id="underlying-probabilistic-model">Underlying probabilistic model</h2>
<p>The underlying probabilistic model when using a logistic regression is thus:</p>
<p>Let <script type="math/tex">\rve{X}</script> a random vector whose first component is always <script type="math/tex">1</script> (this is our bias-term). Let <script type="math/tex">\linparamv_\text{true}</script> be a vector and let <script type="math/tex">\rva{Y} \distributed Bern(p(\rve{X}))</script> be a Bernoulli random variable with probability of success <script type="math/tex">p(\rve{X}) = \logit(\linparamv_\text{true} \cdot \rve{X})</script>.</p>
<p>Our dataset <script type="math/tex">S</script> is made of <script type="math/tex">\ndataset</script> i.i.d. samples from the random vector <script type="math/tex">(\rve{X}, \rva{Y})</script>:</p>
<script type="math/tex; mode=display">S = \{(\ninputvec{\idataset}, \ioutputval{\idataset}) \iid (\rve{X}, \rva{Y}) \mid \idataset \leq \ndataset \}</script>
<p>Hence, for each <script type="math/tex">\idataset \leq \ndataset</script>, we know that <script type="math/tex">\ioutputval{\idataset}</script> is an observation drawn from a <script type="math/tex">Bern(\logit(\linparamv_\text{true} \cdot \ninputvec{\idataset}))</script> distribution.</p>
<p>In this setup, the logistic regression predicts the value of the natural parameter <script type="math/tex">\eta = \logit^{-1}(p(\ninputvec{\idataset}))</script> so as to maximize the likelihood of the observed data.</p>
</div>
    </article>
    </div><!-- row -->
    
    <div class="row mt-1">
      <article class="col-lg-8 mx-auto recommendations">
        <p class='title'>Other articles you might like:</p>
        <ul>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/win-extend-screen.html">Keyboard shortcut and command line utility to switch display (Windows)</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/wsl-dev-environment-2020.html">Using WSL-2 as a dev environment</a></li>
          
            <li class="en"><img class="flag-icon" src="//julienharbulot.com/images/languages/en.png"> <a href="//julienharbulot.com/bash-completion.html">Faster workflow with bash completion scripts</a></li>
          
        </ul>
      </article>
    </div>
    
    
    <div class="row mb=5 mt-5">
      <article class="col-lg-8 mx-auto">
        <div id="hyvor-talk-view"></div>
        <script type="text/javascript">
            var HYVOR_TALK_WEBSITE = '625';
            var HYVOR_TALK_CONFIG = {
                url: 'logistic-regression.html',
                id: 'logistic-regression.html'
            };
        </script>
      </article>
    </div><!-- row -->
    
    <footer class="row">
        <div class="col-lg-8 mx-auto text-center">
          <p><small>
          
            Last updated: 01/14/21 <br/>
          
          
          Copyright &copy; 2021 Julien Harbulot
          </small></p>
        </div>
    </footer>
    </div>

  <script>
  // bootstrap table
  tables = document.getElementsByTagName('table');
  for (i = 0; i < tables.length; i++) {
    tables[i].classList.add('table');
    tables[i].classList.add('table-bordered');
  }

  // Paragraphs that contain only images are marked with custom class for styling
  ps = document.getElementsByTagName('p');
  Array.from(ps).forEach(function(p){
    if (p.getElementsByTagName('img').length > 0 && p.textContent.trim().length == 0) {
        p.classList.add('img-container');
    }
  });
  </script>


    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    <script>
        prev_onload_a = window.onload;
        window.onload = function() {
            if (prev_onload_a) {
                prev_onload_a();
            }
            var navlinks = document.getElementsByClassName("nav-link");
            var i;
            for (i = 0; i < navlinks.length; i++) {
                const target = new URL(navlinks[i].href)
                if (location.pathname == target.pathname) {
                    navlinks[i].classList.add('active')
                }
            }
        }
    </script>    

    

<script async type="text/javascript" src="//talk.hyvor.com/web-api/embed"></script>


    </body>
</html>